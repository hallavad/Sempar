// Signature file for parser generated by fsyacc
module Parser
type token = 
  | EOF
  | WHEN
  | GET
  | TASK
  | PROJECT_PROPERTY
  | PRECISION
  | DESTINATION
  | TRANSFORMATION
  | SOURCES
  | RULE
  | PROJECT_TYPES
  | EQUAL
  | DOT
  | COMMA
  | COLON
  | ID of (string)
  | STRING of (string)
  | INT of (int)
type tokenId = 
    | TOKEN_EOF
    | TOKEN_WHEN
    | TOKEN_GET
    | TOKEN_TASK
    | TOKEN_PROJECT_PROPERTY
    | TOKEN_PRECISION
    | TOKEN_DESTINATION
    | TOKEN_TRANSFORMATION
    | TOKEN_SOURCES
    | TOKEN_RULE
    | TOKEN_PROJECT_TYPES
    | TOKEN_EQUAL
    | TOKEN_DOT
    | TOKEN_COMMA
    | TOKEN_COLON
    | TOKEN_ID
    | TOKEN_STRING
    | TOKEN_INT
    | TOKEN_end_of_input
    | TOKEN_error
type nonTerminalId = 
    | NONTERM__startstart
    | NONTERM_start
    | NONTERM_precision
    | NONTERM_rule_list
    | NONTERM_rule
    | NONTERM_rule_name
    | NONTERM_types
    | NONTERM_type_list
    | NONTERM_sources
    | NONTERM_source_list
    | NONTERM_source
    | NONTERM_transformations
    | NONTERM_destination
    | NONTERM_property
/// This function maps tokens to integer indexes
val tagOfToken: token -> int

/// This function maps integer indexes to symbolic token ids
val tokenTagToTokenId: int -> tokenId

/// This function maps production indexes returned in syntax errors to strings representing the non terminal that would be produced by that production
val prodIdxToNonTerminal: int -> nonTerminalId

/// This function gets the name of a token as a string
val token_to_string: token -> string
val start : (FSharp.Text.Lexing.LexBuffer<'cty> -> token) -> FSharp.Text.Lexing.LexBuffer<'cty> -> (Diagnostics<DataModel.Rules>) 
